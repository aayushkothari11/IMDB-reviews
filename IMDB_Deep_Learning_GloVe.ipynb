{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_Deep_Learning_GloVe.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMxq7Z2hQL6Z",
        "colab_type": "code",
        "outputId": "94e1e342-ab2e-4b88-c196-ac572d101535",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "!pip install PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileId = drive.CreateFile({'id': '#'}) \n",
        "print(fileId['title'])  # dataset.zip\n",
        "fileId.GetContentFile('temp.zip')  # Save Drive file as a local file\n",
        "\n",
        "!unzip temp.zip -d ./"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.6.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.5)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.5)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n",
            "imdb_master.zip\n",
            "Archive:  temp.zip\n",
            "replace ./imdb_master.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: ./imdb_master.csv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGAScVyFQVj5",
        "colab_type": "code",
        "outputId": "a532244c-ba64-4864-f059-4adf05410d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# GloVe file\n",
        "\n",
        "fileId = drive.CreateFile({'id': '#'}) \n",
        "print(fileId['title'])  # dataset.zip\n",
        "fileId.GetContentFile('glove6b100dtxt.zip')  # Save Drive file as a local file\n",
        "\n",
        "!unzip glove6b100dtxt.zip -d ./\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "glove6b100dtxt.zip\n",
            "Archive:  glove6b100dtxt.zip\n",
            "  inflating: ./glove.6B.100d.txt     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxGycjffQzUn",
        "colab_type": "code",
        "outputId": "4d8c45d2-04f1-4957-8367-0765e8c68c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pd9a0SmpQ4SD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('imdb_master.csv', encoding = \"ISO-8859-1\")\n",
        "del df['Unnamed: 0']\n",
        "del df['file']\n",
        "del df['type']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RKFD117Q6jl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.loc[0:49999]\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnAEAwzrQ8Xg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_reviews(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    my_stopwords = stopwords.words('english') \n",
        "    text = text.replace(\"<br >\", \"\")\n",
        "    text = text.replace(\"</br >\", \"\")        \n",
        "    text = re.sub('[^a-zA-Z]',' ', text)\n",
        "    text = text.lower() \n",
        "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
        "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
        "    text = [word for word in text if not word in my_stopwords]\n",
        "    text = \" \".join(text)\n",
        "    return text  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PChGmoh1RCkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"review\"]=df.review.apply(lambda x: clean_reviews(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gY4a0Q37RFRq",
        "colab_type": "code",
        "outputId": "cfd2bf44-6f2f-4ec1-d225-cf7e226b43a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>remember old kung fu movie use watch friday sa...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stick around  one brief series film pair bobb...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>discovery channel animal planet must ashamed  ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>like many western pennsylvania history buff  r...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>best original show see year  watch fall love  ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review label\n",
              "0  remember old kung fu movie use watch friday sa...   neg\n",
              "1   stick around  one brief series film pair bobb...   neg\n",
              "2  discovery channel animal planet must ashamed  ...   neg\n",
              "3  like many western pennsylvania history buff  r...   neg\n",
              "4  best original show see year  watch fall love  ...   pos"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhDNaNHORHOk",
        "colab_type": "code",
        "outputId": "c124af64-1f7b-4691-bf02-82b5da5a309d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df[\"label\"] = df[\"label\"].map({'pos': 1, 'neg': 0})\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>remember old kung fu movie use watch friday sa...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>stick around  one brief series film pair bobb...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>discovery channel animal planet must ashamed  ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>like many western pennsylvania history buff  r...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>best original show see year  watch fall love  ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  remember old kung fu movie use watch friday sa...      0\n",
              "1   stick around  one brief series film pair bobb...      0\n",
              "2  discovery channel animal planet must ashamed  ...      0\n",
              "3  like many western pennsylvania history buff  r...      0\n",
              "4  best original show see year  watch fall love  ...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMfMxlZnRYEk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embeddings_index = dict()\n",
        "f = open('glove.6B.100d.txt')\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i-dVLyxS9Gm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Bidirectional\n",
        "from keras.layers.embeddings import Embedding\n",
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpbpns4uRgEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = 10000\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(df['review'])\n",
        "sequences = tokenizer.texts_to_sequences(df['review'])\n",
        "data = pad_sequences(sequences, maxlen=150)\n",
        "\n",
        "\n",
        "embedding_matrix = np.zeros((vocabulary_size, 100))\n",
        "for word, index in tokenizer.word_index.items():\n",
        "    if index > vocabulary_size - 1:\n",
        "        break\n",
        "    else:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5hhuD60SLWr",
        "colab_type": "code",
        "outputId": "9cc862fe-591c-4a51-a61e-6dd4cd5f204e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(vocabulary_size, 100, input_length=150, weights=[embedding_matrix], trainable=False))\n",
        "model_glove.add(LSTM(200, dropout=0.2, recurrent_dropout=0.2))\n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model_glove.fit(data, df['label'], validation_split=0.2, epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "40000/40000 [==============================] - 677s 17ms/step - loss: 0.5049 - acc: 0.7508 - val_loss: 0.3781 - val_acc: 0.8360\n",
            "Epoch 2/10\n",
            "40000/40000 [==============================] - 668s 17ms/step - loss: 0.3843 - acc: 0.8299 - val_loss: 0.3580 - val_acc: 0.8445\n",
            "Epoch 3/10\n",
            "40000/40000 [==============================] - 668s 17ms/step - loss: 0.3467 - acc: 0.8490 - val_loss: 0.3179 - val_acc: 0.8660\n",
            "Epoch 4/10\n",
            "40000/40000 [==============================] - 662s 17ms/step - loss: 0.3189 - acc: 0.8613 - val_loss: 0.3010 - val_acc: 0.8703\n",
            "Epoch 5/10\n",
            "40000/40000 [==============================] - 663s 17ms/step - loss: 0.2979 - acc: 0.8718 - val_loss: 0.3259 - val_acc: 0.8612\n",
            "Epoch 6/10\n",
            "40000/40000 [==============================] - 584s 15ms/step - loss: 0.2796 - acc: 0.8810 - val_loss: 0.2996 - val_acc: 0.8656\n",
            "Epoch 7/10\n",
            "40000/40000 [==============================] - 320s 8ms/step - loss: 0.2588 - acc: 0.8920 - val_loss: 0.2888 - val_acc: 0.8783\n",
            "Epoch 8/10\n",
            "40000/40000 [==============================] - 322s 8ms/step - loss: 0.2433 - acc: 0.8997 - val_loss: 0.2951 - val_acc: 0.8811\n",
            "Epoch 9/10\n",
            "40000/40000 [==============================] - 329s 8ms/step - loss: 0.2310 - acc: 0.9057 - val_loss: 0.3007 - val_acc: 0.8850\n",
            "Epoch 10/10\n",
            "40000/40000 [==============================] - 333s 8ms/step - loss: 0.2135 - acc: 0.9129 - val_loss: 0.3054 - val_acc: 0.8717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f35f206ae48>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX0Cmpw0TUBU",
        "colab_type": "code",
        "outputId": "ddd6a4ce-e1e4-4084-c39b-7aa1d7047b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model_glove = Sequential()\n",
        "model_glove.add(Embedding(vocabulary_size, 100, input_length=150, weights=[embedding_matrix], trainable=False))\n",
        "model_glove.add(Dropout(0.2))\n",
        "model_glove.add(Conv1D(64, 5, activation='relu'))\n",
        "model_glove.add(MaxPooling1D(pool_size=4))\n",
        "model_glove.add(Bidirectional(LSTM(200, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model_glove.add(Dense(1, activation='sigmoid'))\n",
        "model_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model_glove.fit(data, df['label'], validation_split=0.2, epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "40000/40000 [==============================] - 296s 7ms/step - loss: 0.4807 - acc: 0.7685 - val_loss: 0.4014 - val_acc: 0.8178\n",
            "Epoch 2/10\n",
            "40000/40000 [==============================] - 294s 7ms/step - loss: 0.3873 - acc: 0.8270 - val_loss: 0.3565 - val_acc: 0.8407\n",
            "Epoch 3/10\n",
            "40000/40000 [==============================] - 293s 7ms/step - loss: 0.3572 - acc: 0.8414 - val_loss: 0.3379 - val_acc: 0.8523\n",
            "Epoch 4/10\n",
            "40000/40000 [==============================] - 294s 7ms/step - loss: 0.3359 - acc: 0.8549 - val_loss: 0.3401 - val_acc: 0.8544\n",
            "Epoch 5/10\n",
            "40000/40000 [==============================] - 293s 7ms/step - loss: 0.3203 - acc: 0.8609 - val_loss: 0.3256 - val_acc: 0.8593\n",
            "Epoch 6/10\n",
            "40000/40000 [==============================] - 292s 7ms/step - loss: 0.3091 - acc: 0.8674 - val_loss: 0.3194 - val_acc: 0.8648\n",
            "Epoch 7/10\n",
            "40000/40000 [==============================] - 293s 7ms/step - loss: 0.2955 - acc: 0.8732 - val_loss: 0.3247 - val_acc: 0.8654\n",
            "Epoch 8/10\n",
            "40000/40000 [==============================] - 292s 7ms/step - loss: 0.2874 - acc: 0.8765 - val_loss: 0.3171 - val_acc: 0.8647\n",
            "Epoch 9/10\n",
            "40000/40000 [==============================] - 292s 7ms/step - loss: 0.2763 - acc: 0.8814 - val_loss: 0.3200 - val_acc: 0.8634\n",
            "Epoch 10/10\n",
            "40000/40000 [==============================] - 293s 7ms/step - loss: 0.2676 - acc: 0.8858 - val_loss: 0.3201 - val_acc: 0.8677\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f349f2b2978>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNDBDITvqHTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
