{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB_DeepNetwork.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "H23m3H_078kB",
        "colab_type": "code",
        "outputId": "7e6db3e8-0bfb-4da6-918d-eb289f794d17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "!pip install PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once in a notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileId = drive.CreateFile({'id': '1fbvd-FVNUvU8xf6hpwYzpBwENpQTPVfl'}) \n",
        "print(fileId['title'])  # dataset.zip\n",
        "fileId.GetContentFile('temp.zip')  # Save Drive file as a local file\n",
        "\n",
        "!unzip temp.zip -d ./"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyDrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (3.13)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (4.1.3)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from PyDrive) (1.6.7)\n",
            "Requirement already satisfied: six>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (1.12.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.4.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.2.5)\n",
            "Requirement already satisfied: httplib2>=0.9.1 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (0.11.3)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->PyDrive) (4.0)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->PyDrive) (3.0.0)\n",
            "imdb_master.zip\n",
            "Archive:  temp.zip\n",
            "replace ./imdb_master.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: ./imdb_master.csv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0YxX3ge8DOQ",
        "colab_type": "code",
        "outputId": "dc0753fc-6640-46f0-9cb2-19d3b16e899f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bct-MmAnq1yn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('imdb_master.csv', encoding = \"ISO-8859-1\")\n",
        "del df['Unnamed: 0']\n",
        "del df['file']\n",
        "del df['type']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TSrpB3U7q9qc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.loc[0:49999]\n",
        "df = df.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4uLljP7rAY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_reviews(text):\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    my_stopwords = stopwords.words('english') \n",
        "    text = text.replace(\"<br >\", \"\")\n",
        "    text = text.replace(\"</br >\", \"\")        \n",
        "    text = re.sub('[^a-zA-Z]',' ', text)\n",
        "    text = text.lower() \n",
        "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
        "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
        "    text = [word for word in text if not word in my_stopwords]\n",
        "    text = \" \".join(text)\n",
        "    return text  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lruJNThNrCVF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[\"review\"]=df.review.apply(lambda x: clean_reviews(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK8TIW0_rESv",
        "colab_type": "code",
        "outputId": "11170659-54e9-4bfe-de14-f4997ddcce9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>first   hardly ever watch swedish movie  actua...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>somehow  movie manage invigorate  bittersweet ...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coach use good  ha move new area get away  tea...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>good  rent buy original  watch someone ha gun ...</td>\n",
              "      <td>neg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great horror comedy michael davis iwas laugh h...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review label\n",
              "0  first   hardly ever watch swedish movie  actua...   pos\n",
              "1  somehow  movie manage invigorate  bittersweet ...   pos\n",
              "2  coach use good  ha move new area get away  tea...   neg\n",
              "3  good  rent buy original  watch someone ha gun ...   neg\n",
              "4  great horror comedy michael davis iwas laugh h...   pos"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et3WjHknrGfn",
        "colab_type": "code",
        "outputId": "c9842316-0b93-44d8-9866-76b4b51b6111",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df[\"label\"] = df[\"label\"].map({'pos': 1, 'neg': 0})\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>first   hardly ever watch swedish movie  actua...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>somehow  movie manage invigorate  bittersweet ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coach use good  ha move new area get away  tea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>good  rent buy original  watch someone ha gun ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>great horror comedy michael davis iwas laugh h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  label\n",
              "0  first   hardly ever watch swedish movie  actua...      1\n",
              "1  somehow  movie manage invigorate  bittersweet ...      1\n",
              "2  coach use good  ha move new area get away  tea...      0\n",
              "3  good  rent buy original  watch someone ha gun ...      0\n",
              "4  great horror comedy michael davis iwas laugh h...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwRzFqpprI09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df[\"review\"], df[\"label\"], test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40DxE8YRrK7Y",
        "colab_type": "code",
        "outputId": "24a23aba-d2e0-42d4-f84e-94bfe571ea1c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation, Bidirectional\n",
        "from keras.layers.embeddings import Embedding\n",
        "import string"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc9Iczcfrogl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary_size = 20000\n",
        "tokenizer = Tokenizer(num_words= vocabulary_size)\n",
        "tokenizer.fit_on_texts(df['review'])\n",
        "sequences = tokenizer.texts_to_sequences(df['review'])\n",
        "data = pad_sequences(sequences, maxlen=200)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIuGiBnCr4iS",
        "colab_type": "code",
        "outputId": "2d3ad52c-6c51-412a-8532-c54963ed36af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocabulary_size, 128, input_length=200))\n",
        "model.add(LSTM(500, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(data, df['label'], validation_split=0.2, epochs=10)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "40000/40000 [==============================] - 1098s 27ms/step - loss: 0.4247 - acc: 0.8102 - val_loss: 0.4582 - val_acc: 0.7851\n",
            "Epoch 2/10\n",
            "40000/40000 [==============================] - 1087s 27ms/step - loss: 0.2724 - acc: 0.8934 - val_loss: 0.3058 - val_acc: 0.8835\n",
            "Epoch 3/10\n",
            "40000/40000 [==============================] - 1060s 26ms/step - loss: 0.1899 - acc: 0.9285 - val_loss: 0.3218 - val_acc: 0.8807\n",
            "Epoch 4/10\n",
            "40000/40000 [==============================] - 1056s 26ms/step - loss: 0.1373 - acc: 0.9497 - val_loss: 0.3343 - val_acc: 0.8841\n",
            "Epoch 5/10\n",
            "40000/40000 [==============================] - 1071s 27ms/step - loss: 0.1008 - acc: 0.9646 - val_loss: 0.3733 - val_acc: 0.8859\n",
            "Epoch 6/10\n",
            "40000/40000 [==============================] - 1063s 27ms/step - loss: 0.0675 - acc: 0.9771 - val_loss: 0.4421 - val_acc: 0.8510\n",
            "Epoch 7/10\n",
            "40000/40000 [==============================] - 1074s 27ms/step - loss: 0.0516 - acc: 0.9823 - val_loss: 0.4708 - val_acc: 0.8757\n",
            "Epoch 8/10\n",
            "40000/40000 [==============================] - 921s 23ms/step - loss: 0.0342 - acc: 0.9885 - val_loss: 0.5597 - val_acc: 0.8781\n",
            "Epoch 9/10\n",
            "40000/40000 [==============================] - 852s 21ms/step - loss: 0.0259 - acc: 0.9915 - val_loss: 0.5397 - val_acc: 0.8779\n",
            "Epoch 10/10\n",
            "40000/40000 [==============================] - 1088s 27ms/step - loss: 0.0247 - acc: 0.9920 - val_loss: 0.5944 - val_acc: 0.8802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f913aadda58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rz1B4xuv-Ri",
        "colab_type": "code",
        "outputId": "46f39a61-816c-4ff8-bd66-92c4a5c21770",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model_conv = Sequential()\n",
        "model_conv.add(Embedding(vocabulary_size, 128, input_length=200))\n",
        "model_conv.add(Dropout(0.2))\n",
        "model_conv.add(Conv1D(256, 5, activation='relu'))\n",
        "model_conv.add(MaxPooling1D(pool_size=4))\n",
        "model_conv.add(Bidirectional(LSTM(500, dropout=0.2, recurrent_dropout=0.2)))\n",
        "model_conv.add(Dense(1, activation='sigmoid'))\n",
        "model_conv.compile(loss='binary_crossentropy', optimizer='adam',    metrics=['accuracy'])\n",
        "\n",
        "model_conv.fit(data, df['label'], validation_split=0.2, epochs=10)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/10\n",
            "40000/40000 [==============================] - 514s 13ms/step - loss: 0.3344 - acc: 0.8492 - val_loss: 0.2637 - val_acc: 0.8872\n",
            "Epoch 2/10\n",
            "40000/40000 [==============================] - 508s 13ms/step - loss: 0.1799 - acc: 0.9318 - val_loss: 0.2829 - val_acc: 0.8901\n",
            "Epoch 3/10\n",
            "40000/40000 [==============================] - 508s 13ms/step - loss: 0.1039 - acc: 0.9631 - val_loss: 0.3028 - val_acc: 0.8877\n",
            "Epoch 4/10\n",
            "40000/40000 [==============================] - 509s 13ms/step - loss: 0.0558 - acc: 0.9820 - val_loss: 0.3846 - val_acc: 0.8781\n",
            "Epoch 5/10\n",
            "40000/40000 [==============================] - 510s 13ms/step - loss: 0.0339 - acc: 0.9895 - val_loss: 0.5249 - val_acc: 0.8804\n",
            "Epoch 6/10\n",
            "40000/40000 [==============================] - 505s 13ms/step - loss: 0.0272 - acc: 0.9914 - val_loss: 0.5782 - val_acc: 0.8762\n",
            "Epoch 7/10\n",
            "40000/40000 [==============================] - 506s 13ms/step - loss: 0.0174 - acc: 0.9945 - val_loss: 0.5759 - val_acc: 0.8727\n",
            "Epoch 8/10\n",
            "40000/40000 [==============================] - 511s 13ms/step - loss: 0.0158 - acc: 0.9944 - val_loss: 0.5928 - val_acc: 0.8762\n",
            "Epoch 9/10\n",
            "40000/40000 [==============================] - 490s 12ms/step - loss: 0.0095 - acc: 0.9970 - val_loss: 0.6673 - val_acc: 0.8764\n",
            "Epoch 10/10\n",
            "40000/40000 [==============================] - 302s 8ms/step - loss: 0.0115 - acc: 0.9962 - val_loss: 0.6301 - val_acc: 0.8786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f912020a278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaXQvSi_qa3B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}